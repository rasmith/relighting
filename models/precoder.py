import numpy as np
import torch
import torch.nn as nn
from torch.utils.checkpoint import checkpoint
class Precoder(nn.Module):
        def __init__(self, input_dims):
            super(Precoder, self).__init__()
            self.input_dims = input_dims
            self.fc0 = nn.Linear(input_dims, 1024)
            self.fc1 = nn.Linear(1024, 4096)
            self.fc2 = nn.Linear(4096, 4096)
            self.deconv3 = nn.ConvTranspose2d(256, 512, kernel_size = (3, 3), padding = 1)
            self.bn3 = nn.BatchNorm2d(512)
            self.conv4 = nn.Conv2d(512, 512, kernel_size = (3, 3), padding = 1)
            self.bn4 = nn.BatchNorm2d(512)
            self.deconv5 = nn.ConvTranspose2d(512, 512, kernel_size = (3, 3), padding = 1)
            self.bn5 = nn.BatchNorm2d(512)
            self.conv6 = nn.Conv2d(512, 512, kernel_size = (3, 3), padding = 1)
            self.bn6 = nn.BatchNorm2d(512)
            self.deconv7 = nn.ConvTranspose2d(512, 256, kernel_size = (5, 5))
            self.bn7 = nn.BatchNorm2d(256)
            self.conv8 = nn.Conv2d(256, 256, kernel_size = (3, 3), padding = 1)
            self.bn8 = nn.BatchNorm2d(256)
            self.deconv9 = nn.ConvTranspose2d(256, 128, kernel_size = (5, 5),\
               stride = 2, padding = 2, output_padding = 1)
            self.bn9 = nn.BatchNorm2d(128)
            self.conv10 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 1)
            self.bn10 = nn.BatchNorm2d(128)
            self.deconv11 = nn.ConvTranspose2d(128, 64, kernel_size = (5, 5),\
              stride = 2, padding = 2, output_padding = 1)
            self.bn11 = nn.BatchNorm2d(64)
            self.conv12 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 1)
            self.bn12 = nn.BatchNorm2d(64)
            self.deconv13 = nn.ConvTranspose2d(64, 32, kernel_size = (5, 5),\
              stride = 2, padding = 2, output_padding = 1)
            self.bn13 = nn.BatchNorm2d(32)
            self.conv14 = nn.Conv2d(32, 32, kernel_size = (3, 3), padding = 1)
            self.bn14 = nn.BatchNorm2d(32)
            self.deconv15 = nn.ConvTranspose2d(32, 16, kernel_size = (5, 5),\
               stride = 2, padding = 2, output_padding = 1)
            self.bn15 = nn.BatchNorm2d(16)
            self.conv16 = nn.Conv2d(16, 3, kernel_size = 3, padding = 1)
            self.sig16 = nn.Sigmoid()
        def forward(self, x):
            x = x.view(-1, 1, 1, 19)
            x = self.fc2(self.fc1(self.fc0(x)))
            x = x.view(-1, 256, 4, 4)
            x = self.deconv3(x)
            x = checkpoint(lambda y: self.bn3(y), x)
            x = self.conv4(x)
            x = checkpoint(lambda y: self.bn4(y), x)
            x = self.deconv5(x)
            x = checkpoint(lambda y: self.bn5(y), x)
            x = self.conv6(x)
            x = checkpoint(lambda y: self.bn6(y), x)
            x = self.deconv7(x)
            x = checkpoint(lambda y: self.bn7(y), x)
            x = self.conv8(x)
            x = checkpoint(lambda y: self.bn8(y), x)
            x = self.deconv9(x)
            x = checkpoint(lambda y: self.bn9(y), x)
            x = self.conv10(x)
            x = checkpoint(lambda y: self.bn10(y), x)
            x = self.deconv11(x)
            x = checkpoint(lambda y: self.bn11(y), x)
            x = self.conv12(x)
            x = checkpoint(lambda y: self.bn12(y), x)
            x = self.deconv13(x)
            x = checkpoint(lambda y: self.bn13(y), x)
            x = self.conv14(x)
            x = checkpoint(lambda y: self.bn14(y), x)
            x = self.deconv15(x)
            x = checkpoint(lambda y: self.bn15(y), x)
            x = self.conv16(x)
            x = self.sig16(x)
            return x
        def estimate_size(self):
            model_parameters = filter(lambda p: p.requires_grad, self.parameters())
            params = sum([np.prod(p.size()) for p in model_parameters])
            return params / (1024*1024)
